---
title: "Airline Satisfaction"
author: 
  - Marc Parcerisa
  - Albert Puiggr√≤s
  - Dani Reverter
output:
    pdf_document: default
    html_document: default
    md_document: 
      variant: markdown_github
editor_options:
  chunk_output_type: console
---

<!-- README.md is generated from AirlineSatisfaction.Rmd. Please edit that file. --> 

This project aims to predict airline passenger satisfaction levels by developing
and analyzing binary regression models. Using a dataset containing customer
demographics, flight details, and satisfaction ratings for various services, the
project explores key factors influencing satisfaction. 

This work is organized as follows: [Section 1](#data-preparation) covers data
preparation, including data transformation and cleaning. [Section 2](#eda)
explores each variable in the dataset in detail, whilst [Section 3](#profiling)
searches for relationships between variables and satisfaction levels. 
[Section 4](#model-building), having studied the data, iteratively builds a
logistic regression model to predict satisfaction. [Section 5](#model-validation)
introduces the validation metrics used, and uses them to compare two of the best
models selected on the previous section. Finally, [Section 6](#conclusion)
gives a brief interpretation of the results.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.path = "images/")
```

```{r, include=FALSE}
# Load libraries
library(FactoMineR)
library(cluster)
library(car)
library(missMDA)
library(corrplot)
library(pROC)
library(ggplot2)
library(PRROC)
```

# 1. Data preparation {#data-preparation}

Data preparation will be broken down into two main steps. The first step 
involves transforming the data into a usable format, converting factors into 
such and removing useless columns, and will be applied to both training and
testing datasets. The second one will focus on cleaning the data, removing
missing values, and outliers, and will be applied only to the training dataset.

## Data transformation

We'll start by defining a new function that will perform the first step of data
preparation. This function will remove the "X" and "id" columns, and convert
most of the columns to factors.

```{r}
prepareDataset <- function(data) {
  "Prepare dataset for analysis"
  # Remove useless columns "X" and "id"
  data$X <- NULL
  data$id <- NULL

  # Convert columns to factors
  data$Gender <- as.factor(data$Gender)
  data$Customer.Type <- as.factor(data$Customer.Type)
  data$Type.of.Travel <- as.factor(data$Type.of.Travel)
  data$Class <- factor(data$Class, levels = c("Eco", "Eco Plus", "Business"), ordered = TRUE)

  stais_cols <- c(
    "Inflight.wifi.service", "Departure.Arrival.time.convenient",
    "Ease.of.Online.booking", "Gate.location", "Food.and.drink",
    "Online.boarding", "Seat.comfort", "Inflight.entertainment",
    "On.board.service", "Leg.room.service", "Baggage.handling",
    "Checkin.service", "Inflight.service", "Cleanliness"
  )
  for (col in stais_cols) {
    data[[col]] <- factor(data[[col]], levels = 0:5, ordered = TRUE)
  }

  data$satisfaction <- as.factor(data$satisfaction)
  return(data)
}
```

Now we'll load the training and testing datasets and apply the `prepareDataset`
function to both.

```{r}
# Load datasets
train <- read.csv("data/train_data.csv")
test <- read.csv("data/test_data.csv")

# Prepare datasets
train <- prepareDataset(train)
test <- prepareDataset(test)
```

```{r, include=FALSE}
rm(prepareDataset)
gc()
```

Let's take a look at the first few rows of the training dataset to ensure that
the transformation was successful.

```{r}
str(train)
```

## Data cleaning

This next step will focus on cleaning the training dataset. We'll start by 
removing duplicate rows, counting and imputing missing values.

```{r}
# Find duplicate rows
duplicates <- train[duplicated(train), ]
cat("Number of duplicate rows:", nrow(duplicates), "\n")
```

```{r, include=FALSE}
rm(duplicates)
gc()
```

We found no duplicates. Let's now count the missing values in each column.

```{r}
# Count missing values
missing_values <- colSums(is.na(train))
for (col in names(missing_values)) {
  if (missing_values[col] > 0) {
    cat("Column", col, "has", missing_values[col], "missing values\n")
  }
}
```

There's 12 missing values in the "Arrival.Delay.in.Minutes" column. As most of
our columns are factors, we would impute them using Multiple Correspondence
Analysis (MCA). However, the dataset at hand is too large for this method to be
feasible. Instead, seeing as the number of missing values is small, we'll
simply remove the rows with missing values.

```{r}
# Remove rows with missing values
before <- nrow(train)
train <- train[complete.cases(train), ]
after <- nrow(train)
cat("Removed", before - after, "rows with missing values\n")
```

```{r, include=FALSE}
rm(before, after, missing_values)
gc()
```

Now that we've removed the rows with missing values, let's check for outliers in
the numerical columns.

```{r}
# Check for outliers
numeric_df <- Filter(is.numeric, train)
# There's 4 numerical columns
par(mfrow = c(2, 2))
for (col in names(numeric_df)) {
  boxplot(numeric_df[[col]], main = col, horizontal = TRUE)

  # Calculate IQR
  q1 <- quantile(numeric_df[[col]], 0.25)
  q3 <- quantile(numeric_df[[col]], 0.75)
  iqr <- q3 - q1

  # Add the lines to the plot
  abline(v = c(q1 - 1.5 * iqr, q3 + 1.5 * iqr), col = "orange")
  abline(v = c(q1 - 3 * iqr, q3 + 3 * iqr), col = "red")

  # Find outliers
  mild_outliers <- which(
    numeric_df[[col]] < (q1 - 1.5 * iqr) & numeric_df[[col]] > (q1 - 3 * iqr) |
      numeric_df[[col]] > (q3 + 1.5 * iqr) & numeric_df[[col]] < (q3 + 3 * iqr)
  )
  severe_outliers <- which(numeric_df[[col]] < (q1 - 3 * iqr) | numeric_df[[col]] > (q3 + 3 * iqr))


  cat("Column", col, "has", length(mild_outliers), "mild outliers and", length(severe_outliers), "severe outliers\n")
}
```

```{r, include=FALSE}
rm(numeric_df, q1, q3, iqr, mild_outliers, severe_outliers, col)
gc()
```

Looking at the boxplots, we can see that there are no severe outliers in neither
"Age" nor "Flight.Distance", but there are some in "Departure.Delay.in.Minutes"
and "Arrival.Delay.in.Minutes". However, none of them look too extreme to be
considered errors. Moreover, knowing as we aim to predict satisfaction, arguably
the more extreme the delays are, the more likely the passenger is to be
dissatisfied, providing valuable modeling information. Therefore, we'll keep
them as they are.

Instead, knowing that the arrival and departure delays must be strongly 
correlated, we'll plot them to check if any anomalies are present, indicating
errors in the data.

```{r}
# Plot departure vs arrival delays
par(mfrow = c(1, 1))
plot(train$Departure.Delay.in.Minutes, train$Arrival.Delay.in.Minutes, xlab = "Departure Delay (min)", ylab = "Arrival Delay (min)")
abline(a = 0, b = 1, col = "red")
```

No points seem to be too far from the red line, so we'll consider them as valid
data points.

Before proceeding, we must note that there is a slight imbalance in the target 
variable "Satisfaction", which could affect the model's performance. We'll
address this issue in later sections.

```{r}
table(train$satisfaction)
```

# 2. Exploratory Data Analysis {#eda}

This section will give a small explanation of each variable in the dataset,
including its type, levels, and distribution. We'll also provide visualizations
to help understand the data better.

```{r, include=FALSE}
# Function to plot pie charts.
piechart <- function(data) {
  tbl <- as.data.frame(table(data))
  print(tbl)
  return(ggplot(tbl, aes(x = "", y = Freq, fill = data)) +
    geom_bar(stat = "identity", width = 1) +
    coord_polar("y", start = 0) +
    theme_void() +
    theme(legend.position = "none") +
    geom_text(aes(label = paste0(data, "\n", round(Freq / sum(Freq) * 100, 2), "%")), position = position_stack(vjust = 0.5)))
}
```

## Variable 1: Gender
This is a Nominal variable with 2 levels (binary). A pie chart shows that the
two levels are well represented.

```{r}
summary(train$Gender)
piechart(train$Gender) # See code for the function definition.
```

## Variable 2: Customer.Type
This is a Nominal variable with 2 levels (binary). Another pie chart shows an
imbalance between the two groups, with the loyal customers group being 4x larger
than the disloyal customer group. Since the imbalance is not large enough to
affect the model, no action is taken.

```{r}
summary(train$Customer.Type)
piechart(train$Customer.Type)
```

## Variable 3: Age
This is a Numeric interval variable. It is visualized by a histogram and a
boxplot to examine its distribution, which appears to be well represented for
people of all ages, with no outliers. Visually, a slight deviation from a normal
distribution (centered at age 40) is seen at the ages 20-30, being slightly
higher represented. 

```{r}
summary(train$Age)
hist(train$Age, breaks = 30, xlab = "Age", main = NULL)
boxplot(train$Age, horizontal = TRUE, xlab = "Age")
```

## Variable 4: Type.of.Travel
This is a Nominal variable with 2 levels (binary). Looking at a pie chart, it
becomes clear that all levels are well represented, with Business travel having
2x the individuals than Personal travel.

```{r}
summary(train$Type.of.Travel)
piechart(train$Type.of.Travel)
```

## Variable 5: Class
This is a Nominal variable with 3 levels. When visualizing it on a pie chart, one
can easily see that one of the levels is underrepresented with only 7.2% of the
observations. Since this is still a significant portion of the observations, no
action was taken.

```{r}
summary(train$Class)
piechart(train$Class)
```

## Variable 6: Flight.Distance
This is a continuous ratio variable. It is visualized by a histogram and a
boxplot to examine its distribution. A few univariate outliers are detected, but
they are not so far from the interquartile range to consider changing or
deleting them. It is clearly not normally distributed, confirmed by the
near-null p-value of the shapiro normallity test.

```{r}
summary(train$Flight.Distance)
hist(train$Flight.Distance, breaks = 30, main = NULL, xlab = "Flight Distance")
boxplot(train$Flight.Distance, horizontal = TRUE, xlab = "Flight Distance")
shapiro.test(train$Flight.Distance)
```

## Variable 7: Inflight.wifi.service
This is the first of many Nominal variables with 6 levels (0 to 5, customer
satisfaction level). It is visualized by a bar plot, in which it is clear that
all levels are well represented.

```{r}
summary(train$Inflight.wifi.service)
plot(train$Inflight.wifi.service, xlab = "Inflight wifi service satisfaction level")
```

##Variable 8: Departure.Arrival.time.convenient
This is another Nominal variable with 6 levels. It is visualized by a bar plot,
in which it is clear that all levels are well represented.

```{r}
summary(train$Departure.Arrival.time.convenient)
plot(train$Departure.Arrival.time.convenient, xlab = "Convinience of Departure and Arrival time satisfaction level")
```

## Variable 9: Ease.of.Online.booking
This is another Nominal variable with 6 levels. It is visualized by a bar plot,
in which it is clear that all levels are well represented.

```{r}
summary(train$Ease.of.Online.booking)
plot(train$Ease.of.Online.booking, xlab = "Ease of Online booking satisfaction level")
```

## Variable 10: Gate.location
This is another Nominal variable with 6 levels. It is visualized by a bar plot.
One of the levels is not represented at all, but is not deleted in case the test
dataset contains observations at this level.

```{r}
summary(train$Gate.location)
plot(train$Gate.location, xlab = "Gate location satisfaction level")
```

## Variable 11: Food.and.drink
This is another Nominal variable with 6 levels. It is visualized by a bar plot.
The 0 level is very underrepresented, but as before is not deleted in case it is
not underrepresented in the test dataset.

```{r}
summary(train$Food.and.drink)
plot(train$Food.and.drink, xlab = "Food and drink satisfaction level")
```

## Variable 12: Online.boarding
This is another Nominal variable with 6 levels. It is visualized by a bar plot,
in which it is clear that all levels are well represented.

```{r}
summary(train$Online.boarding)
plot(train$Online.boarding, xlab = "Online boarding satisfaction level")
```

## Variable 13: Seat.comfort
This is another Nominal variable with 6 levels. It is visualized by a bar plot.
The 0 level is not represented, but as before is not deleted in case it is not
underrepresented in the test dataset.

```{r}
summary(train$Seat.comfort)
plot(train$Seat.comfort, xlab = "Seat comfort satisfaction level")
```

## Variable 14: Inflight.entertainment
This is another Nominal variable with 6 levels. It is visualized by a bar plot.
The 0 level is very underrepresented, but as before is not deleted in case it is
not underrepresented in the test dataset.

```{r}
summary(train$Inflight.entertainment)
plot(train$Inflight.entertainment, xlab = "Inflight entertainment satisfaction level")
```

## Variable 15: On.board.service
This is another Nominal variable with 6 levels. It is visualized by a bar plot.
The 0 level is very underrepresented, but as before is not deleted in case it is
not underrepresented in the test dataset.

```{r}
summary(train$On.board.service)
plot(train$On.board.service, xlab = "On-board service satisfaction level")
```

## Variable 16: Leg.room.service
This is another Nominal variable with 6 levels. It is visualized by a bar plot,
in which it is clear that all levels are well represented.

```{r}
summary(train$Leg.room.service)
plot(train$Leg.room.service, xlab = "Leg room service satisfaction level")
```

## Variable 17: Baggage.handling
This is another Nominal variable with 6 levels. It is visualized by a bar plot.
The 0 level is not represented, but as before is not deleted in case it is
represented in the test dataset. 

```{r}
summary(train$Baggage.handling)
plot(train$Baggage.handling, xlab = "Baggage handling satisfaction level")
```

## Variable 18: Checkin.service
This is another Nominal variable with 6 levels. It is visualized by a bar plot.
The 0 level is not represented, but as before is not deleted in case it is
represented in the test dataset. 

```{r}
summary(train$Checkin.service)
plot(train$Checkin.service, xlab = "Check-in service satisfaction level")
```

## Variable 19: Inflight.service
This is another Nominal variable with 6 levels. It is visualized by a bar plot.
The 0 level is very underrepresented, but as before is not deleted in case it is
not underrepresented in the test dataset.

```{r}
summary(train$Inflight.service)
plot(train$Inflight.service, xlab = "Inflight service satisfaction level")
```

## Variable 20: Cleanliness
This is another Nominal variable with 6 levels. It is visualized by a bar plot.
The 0 level is not represented, but as before is not deleted in case it is
represented in the test dataset. 

```{r}
summary(train$Cleanliness)
plot(train$Cleanliness, xlab = "Cleanliness satisfaction level")
```

## Variable 21: Departure.Delay.in.Minutes
This is a continuous ratio variable. It is visualized by a histogram and a
boxplot to examine its distribution. 56.70% of the observations have a delay of
0 minutes, and the variable clearly doesn't follow a normal distribution,
confirmed by a shapiro test. Due to its nature, it contains a lot of outliers
(almost any observation that is not 0) so no action is taken to change/delete
them, not only because they represent a large percentage of the observations, 
but also because, having some domain knowledge, high amounts of delay will 
probably highly influence the satisfaction level - or lack thereof.

```{r}
summary(train$Departure.Delay.in.Minutes)
mean(train$Departure.Delay.in.Minutes == 0) * 100
hist(train$Departure.Delay.in.Minutes, breaks = 30, main = NULL, xlab = "Departure Delay (min)")
boxplot(train$Departure.Delay.in.Minutes, horizontal = TRUE, xlab = "Departure Delay (min)")
shapiro.test(train$Departure.Delay.in.Minutes)
```

## Variable 22: Arrival.Delay.in.Minutes
This is a continuous ratio variable. It is visualized by a histogram and a
boxplot to examine its distribution. Similarly to the last variable, 55.77%  of
the observations have a delay of 0 minutes, and the variable clearly doesn't
follow a normal distribution, confirmed by a shapiro test. Again, due to its 
nature, it contains a lot of outliers, but no related action is taken.

As explained before (in [section 1](#data-preparation)), as expected, this 
variable is highly correlated with the Departure.Delay.in.Minutes variable.

```{r}
summary(train$Arrival.Delay.in.Minutes)
mean(train$Arrival.Delay.in.Minutes == 0) * 100
hist(train$Arrival.Delay.in.Minutes, breaks = 30, main = NULL, xlab = "Arrival Delay (min)")
boxplot(train$Arrival.Delay.in.Minutes, horizontal = TRUE, xlab = "Arrival Delay (min)")
shapiro.test(train$Arrival.Delay.in.Minutes)
```

## Variable 23: Satisfaction
This is our response variable. It is a Nominal variable with 2 levels (binary).
It is visualized by a bar plot, in which it is clear that all levels are well
represented, although a slight imbalance is present, not high enough to significantly
affect the resulting model.

```{r}
summary(train$satisfaction)
piechart(train$satisfaction)
```

A higher imbalance could affect the model's performance, which could be counteracted
by using techniques such as oversampling (duplicating some observation from the
minority class), undersampling (removing some observations from the majority class),
or, in the fitting process, using higher weights for the "losses" of the minority
class.

# 3. Profiling {#profiling}

To analyze the categorical response variable `satisfaction`, the `catdes` function
from the `FactoMineR` package was used. This function identifies the relationship
between the target variable and the other quantitative and qualitative variables.

```{r}
res.cat <- catdes(train, 23)
res.cat$test.chi2
```

The chi-squared test results show that several qualitative variables are
significantly associated with the satisfaction levels, as indicated by their
extremely low p-values. The variables most strongly associated with satisfaction
(in order of decreasing significance) are `Online.boarding`, `Inflight.wifi.service`,
`Class`, `Type.of.Travel` and `Inflight.entertainment`.

```{r}
res.cat$quanti.var
res.cat$quanti
```

For the quantitative variables, the Eta¬≤ values and p-values provide insight
into their relationship with `satisfaction`. The most influential variables
include `Flight.Distance` (passengers with longer flight distances tend to report
higher satisfaction, as indicated by the positive mean in the satisfied category),
`Age` (older passengers are more likely to report satisfaction, with a higher mean
age in the satisfied category compared to neutral or dissatisfied),
`Arrival.Delay.in.Minutes` and `Departure.Delay.in.Minutes` (both delays are
negatively associated with satisfaction, as expected, though their impact is
relatively small)

Passengers categorized as satisfied have a significantly higher mean in
`Flight.Distance` and `Age` compared to the overall averages.

Passengers categorized as neutral or dissatisfied have lower mean
`Flight.Distance` and `Age`. Both `Departure.Delay.in.Minutes` and
`Arrival.Delay.in.Minutes` are slightly higher.

The analysis reveals that satisfaction is most strongly influenced by
qualitative variables such as `Online.boarding`, `Inflight.wifi.service`, and `Class`.
Among quantitative variables, `Flight.Distance` and `Age` are the most significant
predictors.


# 4. Feature Selection & Model Building {#model-building}

```{r}
numeric_vars <- sapply(train, is.numeric)
summary(train[, numeric_vars])
corr_matrix <- cor(train[, numeric_vars], use = "complete.obs")
corrplot(corr_matrix)

train1 <- train
# CHI-TESTS(Testing independence between two Factors)
variables_to_clean <- c(
  "Gate.location", "Food.and.drink",
  "Inflight.entertainment", "Seat.comfort",
  "On.board.service", "Baggage.handling",
  "Checkin.service", "Inflight.service", "Cleanliness"
)

for (var in variables_to_clean) {
  train1 <- train1[train1[[var]] != "0", ]
  train1[[var]] <- factor(train1[[var]])
}

categorical_vars <- c(
  "Gender",
  "Customer.Type", "Type.of.Travel", "Class",
  "Inflight.wifi.service", "Departure.Arrival.time.convenient",
  "Cleanliness", "Food.and.drink", "Online.boarding",
  "Seat.comfort", "Inflight.entertainment", "On.board.service",
  "Leg.room.service", "Baggage.handling", "Checkin.service"
)

for (var in categorical_vars) {
  contingency_table <- table(train1[[var]], train1$satisfaction)
  chi_test <- chisq.test(contingency_table)
  cat("\nChi-Square Test for", var, "vs Satisfaction:\n")
  print(chi_test)
}
```

Regarding numerical variables, the correlation matrix shows that Age and Flight.
Distance have a low positive correlation (0.1147), indicating minimal 
association between the two variables. The Arrival.Delay.in.Minutes and
Departure.Delay.in.Minutes are highly correlated (0.9676), suggesting a strong
linear relationship between them.

The Chi-Square tests show that categorical variables such as Customer.Type,
Type.of.Travel, Class, Inflight.wifi.service, Cleanliness, Seat.comfort,
Inflight.entertainment, On.board.service, Leg.room.service, Baggage.handling,
and Checkin.service all have highly significant p-values (all < 2.2e-16),
indicating a strong relationship with satisfaction. In contrast, Gender and
Departure.Arrival.time.convenient have less impact, with p-values of 0.6884 and
0.01553, respectively. These results suggest that the most important factors for
modeling satisfaction are related to customer type, travel type, flight class,
and the quality of services like inflight entertainment, wifi, cleanliness, and
comfort during the flight. To perform the Chi-Square test, we had to eliminate
the categories of the categorical variables that were empty.

## Numeric Variables

```{r}
m0 <- glm(satisfaction ~ 1, data = train, family = binomial)

summary(m0)

m1 <- glm(satisfaction ~ Flight.Distance, data = train, family = binomial)

summary(m1)
anova(m0, m1)

m1 <- glm(satisfaction ~ Flight.Distance, data = train, family = binomial)

summary(m1)
anova(m0, m1)

m2 <- glm(satisfaction ~ Flight.Distance + Age, data = train, family = binomial)

summary(m2)
anova(m1, m2)

m3 <- glm(satisfaction ~ Flight.Distance + poly(Age, 2), data = train, family = binomial)

summary(m3)
anova(m2, m3)


m4 <- glm(satisfaction ~ Flight.Distance + poly(Age, 2), data = train, family = binomial)

summary(m4)
anova(m3, m4)


m5 <- glm(satisfaction ~ Flight.Distance + poly(Age, 2) + Arrival.Delay.in.Minutes, data = train, family = binomial)

summary(m5)
anova(m4, m5)
Anova(m5)

marginalModelPlots(m5)
residualPlots(m5)
```

To assess the logistic regression model for the target variable "satisfaction,"
we began with the null model, which included only the intercept, to evaluate the
improvement achieved by adding new predictors. The null deviance of the model
was 6812.3, with an AIC of 6814.3. The first predictor added was
`Flight.Distance`, which significantly improved the model fit, reducing the
deviance to 6355.9 and the AIC to 6359.9. The second numerical variable included
was `Age`, which also led to a notable improvement. To capture non-linear
effects of `Age`, we refined the model by introducing a second-order polynomial
term for `Age`. Finally, we incorporated `Arrival.Delay.in.Minutes`, which
further improved the model, reducing the deviance to 6042.3 and the AIC to 6052.3.

To evaluate the improvement of the models, we used the ANOVA test. The results
indicated that each addition of a predictor significantly improved the model, as
evidenced by the reductions in deviance and corresponding p-values. In summary,
the most critical improvements werethe addition of `Flight.Distance`, the
refinement of `Age` using polynomial terms, and the inclusion of
`Arrival.Delay.in.Minutes`, all of which were confirmed by the ANOVA tests. No significant interaction terms were identified inj the anova test, thus they are not included in the model of numeric variables.

# Factor & Factor Interaction Variables
In this section, we apply the stepwise selection method to find a suitable logistic regression model. We start with an initial model that includes the previous model with the numerical variables and all the factors. Then, the step function iteratively evaluates models by adding or removing predictors to minimize the Akaike Information Criterion (AIC). Following this, we perform residual analysis to assess the model's goodness-of-fit. The result is a simple model we will use later to comper with a model including interactions.

```{r}
par(mfrow = c(1, 1))
# STEP
initial_model <- glm(
  satisfaction ~ Gender + Customer.Type + poly(Age, 2) + Arrival.Delay.in.Minutes + Type.of.Travel +
    Class + Flight.Distance + Inflight.wifi.service +
    Ease.of.Online.booking + Gate.location + Food.and.drink + Online.boarding +
    Seat.comfort + Inflight.entertainment + On.board.service + Leg.room.service +
    Baggage.handling + Checkin.service + Inflight.service + Cleanliness,
  data = train, family = binomial
)

simpler_model <- step(initial_model, direction = "both", trace = 1)

#Step:  AIC=1922.22
#satisfaction ~ Customer.Type + poly(Age, 2) + Type.of.Travel + 
#    Class + Inflight.wifi.service + Ease.of.Online.booking + 
#    Gate.location + Online.boarding + Seat.comfort + Inflight.entertainment + 
#    On.board.service + Leg.room.service + Baggage.handling + 
#    Checkin.service + Inflight.service + Cleanliness

# RESIDUAL ANALYSIS OF THE STEP MODEL
marginalModelPlots(simpler_model)
residualPlots(simpler_model)

coef(simpler_model)
Anova(simpler_model, test = "LR")
AIC(simpler_model)
```

Next, we explore interaction terms between predictors. Starting with a base model that includes all significant predictors identified from the stepwise selection, we systematically examine potential interactions. This code is commented out due to the high computational cost and time it takes to execute.Each pair of predictors is tested by fitting a model that includes their interaction term and comparing it to the base model using an ANOVA test. Interaction terms that significantly improve model fit (p-value < 0.05) are added to the model.

After identifying all significant interactions, we refit the final logistic regression model, now including these interaction terms. To further refine the model, a final stepwise selection is performed to ensure that only the necessary predictors and interactions are retained. For the subsequent steps, we will maintain both the simpler model without interactions and the more complex model with all significant interactions, validating the performance of each.

```{r}
# Define the base formula with no interactions
base_formula <- "Customer.Type + poly(Age, 2) + Type.of.Travel + Class + 
                 Inflight.wifi.service + Ease.of.Online.booking + Gate.location + 
                 Online.boarding + Seat.comfort + Inflight.entertainment + 
                 On.board.service + Leg.room.service + Baggage.handling + 
                 Checkin.service + Inflight.service + Cleanliness"

# List of predictors without interaction terms
predictors <- c("Customer.Type", "poly(Age, 2)", "Type.of.Travel", "Class", 
                "Inflight.wifi.service", "Ease.of.Online.booking", "Gate.location", 
                "Online.boarding", "Seat.comfort", "Inflight.entertainment", 
                "On.board.service", "Leg.room.service", "Baggage.handling", 
                "Checkin.service", "Inflight.service", "Cleanliness")

# Initialize an empty list to store significant interaction terms
significant_interactions <- list()

# Fit the base model using logistic regression (binary outcome: satisfaction)
base_model <- glm(as.formula(paste("satisfaction ~", base_formula)), 
                      data = train, family = binomial)

# Store the AIC of the base model
base_aic <- AIC(base_model)

# Start with the base formula for building the new model
new_model <- base_formula

# Loop over all pairs of predictors to check for significant interactions
#for (i in 1:(length(predictors) - 1)) {
#  for (j in (i + 1):length(predictors)) {
#    # Define the interaction term
#    interaction_term <- paste(predictors[i], predictors[j], sep = ":")
#
#    # Fit the model with the interaction term
#    full_model <- glm(as.formula(paste("satisfaction ~", base_formula, "+", interaction_term)), 
#                      data = train, family = binomial)#
#
#    # Perform ANOVA test to compare models
#    anova_result <- anova(base_model, full_model, test = "Chisq")#
#
#    # Check if the interaction term is significant (p-value < 0.05)
#    if (anova_result$`Pr(>Chi)`[2] < 0.05) {
#      # If the interaction is significant, add it to the list of significant interactions
#      significant_interactions[[length(significant_interactions) + 1]] <- interaction_term
#      
#      # Update the model with the significant interaction term
 #     new_model <- paste0(new_model, "+", interaction_term)
#      
#      base_formula <- paste0(base_formula, "+", interaction_term)
#    }
#  }
#}

# Print the list of significant interactions
#cat("Significant interactions:\n")
#print(significant_interactions)

# Fit the final model with all significant interactions
#new_model <- glm(paste0("satisfaction ~", new_model), data = train, family = binomial)

# Perform final stepwise regression
#stepwise_final_model <- step(new_model, direction = "both", trace = 1)

#Step:  AIC=1420.62
#satisfaction ~ Customer.Type + poly(Age, 2) + Type.of.Travel + 
#    Class + Inflight.wifi.service + Ease.of.Online.booking + 
#    Gate.location + Online.boarding + Seat.comfort + Inflight.entertainment + 
#    On.board.service + Leg.room.service + Baggage.handling + 
#    Checkin.service + Inflight.service + Cleanliness + Customer.Type:poly(Age, 
#    2) + Customer.Type:Inflight.wifi.service + Customer.Type:Gate.location + 
#    Customer.Type:Online.boarding + Customer.Type:Seat.comfort + 
#    Customer.Type:Leg.room.service + Customer.Type:Checkin.service + 
#    Customer.Type:Inflight.service + Customer.Type:Cleanliness + 
#    poly(Age, 2):Online.boarding + poly(Age, 2):Inflight.entertainment + 
#    poly(Age, 2):Inflight.service + poly(Age, 2):Cleanliness + 
#    Type.of.Travel:Class + Type.of.Travel:Inflight.wifi.service + 
#    Type.of.Travel:Ease.of.Online.booking + Type.of.Travel:Online.boarding + 
#    Type.of.Travel:Seat.comfort + Type.of.Travel:Inflight.entertainment + 
#    Type.of.Travel:On.board.service + Type.of.Travel:Baggage.handling + 
#    Type.of.Travel:Checkin.service + Type.of.Travel:Inflight.service + 
#    Class:Inflight.wifi.service + Class:Inflight.entertainment + 
#    Class:On.board.service + Class:Leg.room.service + Type.of.Travel:Gate.location

stepwise_model <- glm(satisfaction ~ Customer.Type + poly(Age, 2) + Type.of.Travel + 
    Class + Inflight.wifi.service + Ease.of.Online.booking + 
    Gate.location + Online.boarding + Seat.comfort + Inflight.entertainment + 
    On.board.service + Leg.room.service + Baggage.handling + 
    Checkin.service + Inflight.service + Cleanliness + Customer.Type:poly(Age, 
    2) + Customer.Type:Inflight.wifi.service + Customer.Type:Gate.location + 
   Customer.Type:Leg.room.service + Customer.Type:Checkin.service + 
    Customer.Type:Inflight.service + Customer.Type:Cleanliness + 
    poly(Age, 2):Online.boarding + poly(Age, 2):Inflight.entertainment + 
   poly(Age, 2):Inflight.service + poly(Age, 2):Cleanliness + 
    Type.of.Travel:Class + Type.of.Travel:Inflight.wifi.service + 
    Type.of.Travel:Ease.of.Online.booking + Type.of.Travel:Online.boarding + 
    Type.of.Travel:Seat.comfort + Type.of.Travel:Inflight.entertainment + 
    Type.of.Travel:On.board.service + Type.of.Travel:Baggage.handling + 
    Type.of.Travel:Checkin.service + Type.of.Travel:Inflight.service + 
    Class:Inflight.wifi.service + Class:Inflight.entertainment + 
    Class:On.board.service + Class:Leg.room.service + Type.of.Travel:Gate.location,
   data = train, family = binomial)

marginalModelPlots(stepwise_model)
residualPlots(stepwise_model)

coef(stepwise_model)
AIC(stepwise_model)

```


# 5. Model Validation {#model-validation}

Using the training dataset, we have built a logistic regression model to predict
passenger satisfaction. Now, we will evaluate the model's performance using the
testing dataset.

Let's start by predicting the satisfaction levels for the testing dataset.

```{r}
Satisfaction.Prob <- predict(stepwise_model, newdata = test, type = "response")
```

Due to the `type="response"` parameter, the new column "Satisfaction.Prob"
contains the predicted probabilities of satisfaction for each passenger. To
decide whether a passenger is satisfied or not, a threshold must be set. For
example, let's set a threshold of 0.5.

```{r}
Predicted.Satisfaction <- ifelse(Satisfaction.Prob > 0.5, "satisfied", "neutral or dissatisfied")
```

And with that, a confusion matrix can be created to evaluate the model's
performance.

```{r}
conf_matrix <- table(test$satisfaction, Predicted.Satisfaction)
```

To calculate the performance metrics, we start from the confusion matrix's elements:

```{r}
TP <- conf_matrix[2, 2]
TN <- conf_matrix[1, 1]
FP <- conf_matrix[1, 2]
FN <- conf_matrix[2, 1]
```

We define "Accuracy" as the Correct Classification Rate:

$$
CCR = \frac{TP + TN}{TP + TN + FP + FN}
$$

```{r}
(TP + TN) / sum(conf_matrix)
```

We define "Sensitivity" or "Recall" as the True Positive Rate:

$$
TPR = \frac{TP}{TP + FN}
$$

```{r}
TP / (TP + FN)
```

And we define "Fall-out" as the False Positive Rate:

$$
FPR = \frac{FP}{FP + TN}
$$

```{r}
FP / (FP + TN)
```

The process of designing a model and choosing a threshold consists of a careful
trade-off between sensitivity and fall-out. If we plot these metrics against
different thresholds, we can visualize this trade-off in what is known as a
Receiver Operating Characteristic (ROC) curve:

```{r}
par(mfrow = c(1, 1))
roc <- roc(test$satisfaction, Satisfaction.Prob, quiet = TRUE)
plot(roc, main = "ROC Curve", col = "blue")
polygon(c(roc$specificities, 0), c(roc$sensitivities, 0), col = adjustcolor("blue", alpha.f = 0.2), border = NA)
```

A model with perfect discrimination has an ROC curve that passes through the
upper-left corner, whilst a model with no discrimination has an ROC curve that
passes through the diagonal. Thus, the area under the ROC curve (AUC) is a
good measure of the model's performance. The closer the AUC is to 1, the better
the model is at distinguishing between satisfied and dissatisfied passengers.

```{r}
auc(roc)
```

This high AUC value indicates that the model is fairly good at distinguishing
between satisfied and dissatisfied passengers.

## Which model should we choose?

In the previous section, we arrived at two models: `stepwise_model`, which was 
constructed by minimizing the Akaike Information Criterion (AIC) using the 
`step` function, and `simpler_model`, which was a manually constructed model
based On the most significant variables of the former.

The following code executes a prediction on the testing dataset for the latter 
model, and computes the ROC curve.

```{r}
Satisfaction.Prob.Simpler <- predict(simpler_model, newdata = test, type = "response")
roc.Simpler <- roc(test$satisfaction, Satisfaction.Prob.Simpler, quiet = TRUE)
plot(roc.Simpler, col = "red", main = "ROC Curves")
polygon(c(roc.Simpler$specificities, 0), c(roc.Simpler$sensitivities, 0), col = adjustcolor("red", alpha.f = 0.2), border = NA)
lines(roc, col = "blue", lwd = 2)
polygon(c(roc$specificities, 0), c(roc$sensitivities, 0), col = adjustcolor("blue", alpha.f = 0.2), border = NA)
legend(
  "bottomright",
  legend = c("Stepwise Model", "Simpler Model"),
  col = c("blue", "red"), lwd = 2, fill = adjustcolor(c("blue", "red"), alpha.f = 0.2)
)
```

When comparing the two curves, we can see that ....

<!-- I cannot run the stepwise model!!!! I cannot compare the two curves -->

And looking at the areas under the ROC curves, it becomes clear that, indeed,
the stepwise model is slightly better, but it's complexity might not be worth
the small improvement in performance, according to the AUC criterion.

```{r}
print(paste("Area under the stepwise curve:", auc(roc)))
print(paste("Area under the simpler curve:", auc(roc.Simpler)))
```

To further compare them, let's first choose a suitable threshold for both of them.
We'll choose the threshold that maximizes the F1 score, which is the harmonic
mean of precision and recall, computed as follows:

$$
F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
$$

```{r}
f1_computer <- function(expected, probs) {
  return(function(threshold) {
    pred <- factor(
      ifelse(probs > threshold, "satisfied", "neutral or dissatisfied"),
      levels = c("satisfied", "neutral or dissatisfied")
    )
    conf <- table(expected, pred)
    TP <- conf["satisfied", "satisfied"]
    FP <- conf["neutral or dissatisfied", "satisfied"]
    FN <- conf["satisfied", "neutral or dissatisfied"]
    precision <- TP / (TP + FP)
    recall <- TP / (TP + FN)
    return(2 * precision * recall / (precision + recall + 1e-10)) # Avoid division by zero
  })
}

thresholds <- seq(0, 1, 0.01)
stepwise_f1 <- sapply(thresholds, f1_computer(test$satisfaction, Satisfaction.Prob))
simpler_f1 <- sapply(thresholds, f1_computer(test$satisfaction, Satisfaction.Prob.Simpler))

plot(thresholds, stepwise_f1, type = "l", col = "blue", xlab = "Threshold", ylab = "F1 Score", main = "F1 Score vs Threshold")
lines(thresholds, simpler_f1, col = "red")
legend("topright", legend = c("Stepwise Model", "Simpler Model"), col = c("blue", "red"), lwd = 2)
```

The thresholds are:

```{r}
stepwise_threshold <- thresholds[which.max(stepwise_f1)]
simpler_threshold <- thresholds[which.max(simpler_f1)]
print(paste("Stepwise Model Threshold:", stepwise_threshold))
print(paste("Simpler Model Threshold:", simpler_threshold))
```

Now, using them, here's their confusion matrices:

```{r}
stepwise_pred <- factor(
  ifelse(Satisfaction.Prob > stepwise_threshold, "satisfied", "neutral or dissatisfied"),
  levels = c("satisfied", "neutral or dissatisfied")
)
simpler_pred <- factor(
  ifelse(Satisfaction.Prob.Simpler > simpler_threshold, "satisfied", "neutral or dissatisfied"),
  levels = c("satisfied", "neutral or dissatisfied")
)

stepwise_conf_matrix <- table(test$satisfaction, stepwise_pred)
stepwise_conf_matrix
simpler_conf_matrix <- table(test$satisfaction, simpler_pred)
simpler_conf_matrix
```

And their accuracies:

```{r}
stepwise_accuracy <- sum(diag(stepwise_conf_matrix)) / sum(stepwise_conf_matrix)
stepwise_accuracy
simpler_accuracy <- sum(diag(simpler_conf_matrix)) / sum(simpler_conf_matrix)
simpler_accuracy
```

As we can see...
<!-- Comment on which model has the highest threshold, and the highest accuracy -->


# 6. Conclusion {#conclusion}

<!-- Interpret the results :) -->
