---
title: "Airline Satisfaction"
author: 
  - Marc Parcerisa
  - Albert Puiggr√≤s
  - Dani Reverter
output:
    pdf_document: default
    html_document: default
    md_document: 
      variant: markdown_github
editor_options:
  chunk_output_type: console
---

<!-- README.md is generated from AirlineSatisfaction.Rmd. Please edit that file. --> 

This project aims to predict airline passenger satisfaction levels by developing
and analyzing binary regression models. Using a dataset containing customer
demographics, flight details, and satisfaction ratings for various services, the
project explores key factors influencing satisfaction. The workflow encompasses
comprehensive data preparation, including cleaning, transformation, and
profiling, followed by exploratory data analysis and model building.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.path = "images/")
```

```{r, include=FALSE}
# Load libraries
library(FactoMineR)
library(cluster)
library(missMDA)
library(corrplot)
```

# Data preparation

Data preparation will be broken down into two main steps. The first step 
involves transforming the data into a usable format, converting factors into 
such and removing useless columns, and will be applied to both training and
testing datasets. The second one will focus on cleaning the data, removing
missing values, and outliers, and will be applied only to the training dataset.

## Data transformation

We'll start by defining a new function that will perform the first step of data
preparation. This function will remove the "X" and "id" columns, and convert
most of the columns to factors.

```{r}
prepareDataset <- function(data) {
  "Prepare dataset for analysis"
  # Remove useless columns "X" and "id"
  data$X <- NULL
  data$id <- NULL

  # Convert columns to factors
  data$Gender <- as.factor(data$Gender)
  data$Customer.Type <- as.factor(data$Customer.Type)
  data$Type.of.Travel <- as.factor(data$Type.of.Travel)
  data$Class <- factor(data$Class, levels = c("Eco", "Eco Plus", "Business"), ordered = TRUE)

  stais_cols <- c(
    "Inflight.wifi.service", "Departure.Arrival.time.convenient",
    "Ease.of.Online.booking", "Gate.location", "Food.and.drink",
    "Online.boarding", "Seat.comfort", "Inflight.entertainment",
    "On.board.service", "Leg.room.service", "Baggage.handling",
    "Checkin.service", "Inflight.service", "Cleanliness"
  )
  for (col in stais_cols) {
    data[[col]] <- factor(data[[col]], levels = 0:5, ordered = TRUE)
  }

  data$satisfaction <- as.factor(data$satisfaction)
  return(data)
}
```

Now we'll load the training and testing datasets and apply the `prepareDataset`
function to both.

```{r}
# Load datasets
train <- read.csv("data/train_data.csv")
test <- read.csv("data/test_data.csv")

# Prepare datasets
train <- prepareDataset(train)
test <- prepareDataset(test)
```

```{r, include=FALSE}
rm(prepareDataset)
gc()
```

Let's take a look at the first few rows of the training dataset to ensure that
the transformation was successful.

```{r}
str(train)
```

## Data cleaning

This next step will focus on cleaning the training dataset. We'll start by 
removing duplicate rows, counting and imputing missing values.

```{r}
# Find duplicate rows
duplicates <- train[duplicated(train), ]
cat("Number of duplicate rows:", nrow(duplicates), "\n")
```

```{r, include=FALSE}
rm(duplicates)
gc()
```

We found no duplicates. Let's now count the missing values in each column.

```{r}
# Count missing values
missing_values <- colSums(is.na(train))
for (col in names(missing_values)) {
  if (missing_values[col] > 0) {
    cat("Column", col, "has", missing_values[col], "missing values\n")
  }
}
```

There's 12 missing values in the "Arrival.Delay.in.Minutes" column. As most of
our columns are factors, we would impute them using Multiple Correspondence
Analysis (MCA). However, the dataset at hand is too large for this method to be
feasible. Instead, seeing as the number of missing values is small, we'll
simply remove the rows with missing values.

```{r}
# Remove rows with missing values
before <- nrow(train)
train <- train[complete.cases(train), ]
after <- nrow(train)
cat("Removed", before - after, "rows with missing values\n")
```

```{r, include=FALSE}
rm(before, after, missing_values)
gc()
```

Now that we've removed the rows with missing values, let's check for outliers in
the numerical columns.

```{r}
# Check for outliers
numeric_df <- Filter(is.numeric, train)
# There's 4 numerical columns
par(mfrow = c(2, 2))
for (col in names(numeric_df)) {
  boxplot(numeric_df[[col]], main = col, horizontal = TRUE)

  # Calculate IQR
  q1 <- quantile(numeric_df[[col]], 0.25)
  q3 <- quantile(numeric_df[[col]], 0.75)
  iqr <- q3 - q1

  # Add the lines to the plot
  abline(v = c(q1 - 1.5 * iqr, q3 + 1.5 * iqr), col = "orange")
  abline(v = c(q1 - 3 * iqr, q3 + 3 * iqr), col = "red")

  # Find outliers
  mild_outliers <- which(
    numeric_df[[col]] < (q1 - 1.5 * iqr) & numeric_df[[col]] > (q1 - 3 * iqr) |
      numeric_df[[col]] > (q3 + 1.5 * iqr) & numeric_df[[col]] < (q3 + 3 * iqr)
  )
  severe_outliers <- which(numeric_df[[col]] < (q1 - 3 * iqr) | numeric_df[[col]] > (q3 + 3 * iqr))


  cat("Column", col, "has", length(mild_outliers), "mild outliers and", length(severe_outliers), "severe outliers\n")
}
```

```{r, include=FALSE}
rm(numeric_df, q1, q3, iqr, mild_outliers, severe_outliers, col)
gc()
```

Looking at the boxplots, we can see that there are no severe outliers in neither
"Age" nor "Flight.Distance", but there are some in "Departure.Delay.in.Minutes"
and "Arrival.Delay.in.Minutes". However, none of them look too extreme to be
considered errors. Moreover, knowing as we aim to predict satisfaction, arguably
the more extreme the delays are, the more likely the passenger is to be
dissatisfied, providing valuable modeling information. Therefore, we'll keep
them as they are.

Instead, knowing that the arrival and departure delays must be strongly 
correlated, we'll plot them to check if any anomalies are present, indicating
errors in the data.

```{r}
# Plot departure vs arrival delays
par(mfrow = c(1, 1))
plot(train$Departure.Delay.in.Minutes, train$Arrival.Delay.in.Minutes, xlab = "Departure Delay (min)", ylab = "Arrival Delay (min)")
abline(a = 0, b = 1, col = "red")
```

No points seem to be too far from the red line, so we'll consider them as valid
data points.

Before proceeding, we must note that there is a slight imbalance in the target 
variable "Satisfaction", which could affect the model's performance. We'll
address this issue in later sections.

```{r}
table(train$satisfaction)
```


# Feature Selection
```{r}
numeric_vars <- sapply(train, is.numeric)
summary(train[, numeric_vars])
corr_matrix <- cor(train[, numeric_vars], use = "complete.obs")
corrplot(corr_matrix)

train1 <- train
# CHI-TESTS(Testing independence between two Factors)
variables_to_clean <- c(
  "Gate.location", "Food.and.drink",
  "Inflight.entertainment", "Seat.comfort",
  "On.board.service", "Baggage.handling",
  "Checkin.service", "Inflight.service", "Cleanliness"
)

for (var in variables_to_clean) {
  train1 <- train1[train1[[var]] != "0", ]
  train1[[var]] <- factor(train1[[var]])
}

categorical_vars <- c(
  "Gender",
  "Customer.Type", "Type.of.Travel", "Class",
  "Inflight.wifi.service", "Departure.Arrival.time.convenient",
  "Cleanliness", "Food.and.drink", "Online.boarding",
  "Seat.comfort", "Inflight.entertainment", "On.board.service",
  "Leg.room.service", "Baggage.handling", "Checkin.service"
)

for (var in categorical_vars) {
  contingency_table <- table(train1[[var]], train1$satisfaction)
  chi_test <- chisq.test(contingency_table)
  cat("\nChi-Square Test for", var, "vs Satisfaction:\n")
  print(chi_test)
}
```


Regarding numerical varaibles, the correlation matrix shows that Age and Flight.
Distance have a low positive correlation (0.1147), indicating minimal 
association between the two variables. The Arrival.Delay.in.Minutes and
Departure.Delay.in.Minutes are highly correlated (0.9676), suggesting a strong
linear relationship between them.

The Chi-Square tests show that categorical variables such as Customer.Type,
Type.of.Travel, Class, Inflight.wifi.service, Cleanliness, Seat.comfort,
Inflight.entertainment, On.board.service, Leg.room.service, Baggage.handling,
and Checkin.service all have highly significant p-values (all < 2.2e-16),
indicating a strong relationship with satisfaction. In contrast, Gender and
Departure.Arrival.time.convenient have less impact, with p-values of 0.6884 and
0.01553, respectively. These results suggest that the most important factors for
modeling satisfaction are related to customer type, travel type, flight class,
and the quality of services like inflight entertainment, wifi, cleanliness, and
comfort during the flight. To perform the Chi-Square test, we had to eliminate
the categories of the categorical variables that were empty.

```{r}
# NUMERIC VARIABLES
m0 <- glm(satisfaction ~ 1, data = train, family = binomial)

summary(m0)

m1 <- glm(satisfaction ~ Flight.Distance, data = train, family = binomial)

summary(m1)
anova(m0, m1)

m1 <- glm(satisfaction ~ Flight.Distance, data = train, family = binomial)

summary(m1)
anova(m0, m1)

m2 <- glm(satisfaction ~ Flight.Distance + Age, data = train, family = binomial)

summary(m2)
anova(m1, m2)

m3 <- glm(satisfaction ~ Flight.Distance + poly(Age, 2), data = train, family = binomial)

summary(m3)
anova(m2, m3)


m4 <- glm(satisfaction ~ Flight.Distance + poly(Age, 2), data = train, family = binomial)

summary(m4)
anova(m3, m4)


m5 <- glm(satisfaction ~ Flight.Distance + poly(Age, 2) + Arrival.Delay.in.Minutes, data = train, family = binomial)

summary(m5)
anova(m4, m5)
Anova(m5)

marginalModelPlots(m5)
residualPlots(m5)
```

To assess the logistic regression model for the target variable "satisfaction,"
we began with the null model, which included only the intercept, to evaluate the
improvement achieved by adding new predictors. The null deviance of the model
was 6812.3, with an AIC of 6814.3. The first predictor added was
`Flight.Distance`, which significantly improved the model fit, reducing the
deviance to 6355.9 and the AIC to 6359.9. The second numerical variable included
was `Age`, which also led to a notable improvement. To capture non-linear
effects of `Age`, we refined the model by introducing a second-order polynomial
term for `Age`. Finally, we incorporated `Arrival.Delay.in.Minutes`, which
further improved the model, reducing the deviance to 6042.3 and the AIC to 6052.3.

To evaluate the improvement of the models, we used the ANOVA test. The results
indicated that each addition of a predictor significantly improved the model, as
evidenced by the reductions in deviance and corresponding p-values. In summary,
the most critical improvements werethe addition of `Flight.Distance`, the
refinement of `Age` using polynomial terms, and the inclusion of
`Arrival.Delay.in.Minutes`, all of which were confirmed by the ANOVA tests.

# Model Validation

Using the training dataset, we have built a logistic regression model to predict
passenger satisfaction. Now, we will evaluate the model's performance using the
testing dataset.

Let's start by predicting the satisfaction levels for the testing dataset.

```{r}
test$Satisfaction.Prob <- predict(model, newdata = test, type = "response")
```

Due to the `type="response"` parameter, the new column "Satisfaction.Prob"
contains the predicted probabilities of satisfaction for each passenger. To
decide whether a passenger is satisfied or not, a threshold must be set. For
example, let's set a threshold of 0.5.

```{r}
test$Predicted.Satisfaction <- ifelse(test$Satisfaction.Prob > 0.5, "satisfied", "neutral or dissatisfied")
```

And with that, a confusion matrix can be created to evaluate the model's
performance.

```{r}
conf_matrix <- table(test$satisfaction, test$Predicted.Satisfaction)
```

To calculate the performance metrics, we start from the confusion matrix's elements:

```{r}
TP <- conf_matrix[2, 2]
TN <- conf_matrix[1, 1]
FP <- conf_matrix[1, 2]
FN <- conf_matrix[2, 1]
```

We define "Accuracy" as the Correct Classification Rate:

$$
CCR = \frac{TP + TN}{TP + TN + FP + FN}
$$

```{r}
(TP + TN) / sum(conf_matrix)
```

We define "Sensitivity" or "Recall" as the True Positive Rate:

$$
TPR = \frac{TP}{TP + FN}
$$

```{r}
TP / (TP + FN)
```

And we define "Fall-out" as the False Positive Rate:

$$
FPR = \frac{FP}{FP + TN}
$$

```{r}
FP / (FP + TN)
```

The process of designing a model and choosing a threshold consists of a careful
trade-off between sensitivity and fall-out. If we plot these metrics against
different thresholds, we can visualize this trade-off in what is known as a
Receiver Operating Characteristic (ROC) curve:

```{r}
par(mfrow = c(1, 1))
roc <- roc(test$satisfaction, test$Predicted.Satisfaction)
# Set limits to 0..1
plot(roc, main = "ROC Curve", col = "blue")
```

A model with perfect discrimination has an ROC curve that passes through the
upper-left corner, whilst a model with no discrimination has an ROC curve that
passes through the diagonal. Thus, the area under the ROC curve (AUC) is a
good measure of the model's performance. The closer the AUC is to 1, the better
the model is at distinguishing between satisfied and dissatisfied passengers.

```{r}
auc(roc)
```

This high AUC value indicates that the model is fairly good at distinguishing
between satisfied and dissatisfied passengers.

